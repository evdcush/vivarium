{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging and plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous practical sessions we saw how to define routines and attach them to the agents. Here we are going to see how to use such routines to record data perceived or produced by the agents. This will allow the plotting of figures in the notebook. This can also be useful to better visualize what is happening in your simulation and help you debugging it. \n",
    "\n",
    "Let's start with a simple example where we record the values returned by both proximeters through time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start the simulator and create a controller object as usual (we'll use the same scene as in session 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivarium.controllers.notebook_controller import NotebookController\n",
    "from vivarium.utils.handle_server_interface import start_server_and_interface, stop_server_and_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_server_and_interface(scene_name=\"session_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = NotebookController()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will assign variables to each agent present in the scene. The cell below has the exact same effect as the one we use near the start of session 4, it is just shorter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0, agent_1, agent_2 = controller.agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add some logs to the first agent. Recording data is realized by the `add_log` method of the agent, which requires two arguments: an arbitrary label of the recorded data, what we call a *topic*, and the data to be recorded. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the number 1 in a topic called 'test' on agent_0\n",
    "agent_0.add_log(\"test\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stores the data `1` in a topic that we arbitrarily call `\"test\"`. We can retrieve this data by using the `get_log` function , which requires as argument the name of the topic (`\"test\"` in this example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `agent_0.get_log(\"test\")` returns the list of the data recorded in the topic `\"test\"` by `agent_0`. Here it prints `[1]`, a list containing the only data we have stored before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add another data to the same topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.add_log(\"test\", 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And retrieve the data recorded on this topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second value we have added, `42`, has been appended to the list, which now contains the two recorded data.\n",
    "\n",
    "We can add another value to another topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.add_log(\"another_topic\", 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and retrieve it using `get_log`, this time with the name of this new topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"another_topic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the data recorded before in the topic `\"test\"` is still accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names chosen for the topics are completely arbitrary. They are just labels that you choose for organizing the recorded data according to their meaning. The type of data recorded in a topic is also arbitrary: above we recorded integer values, but we could instead record strings or whatever.\n",
    "\n",
    "These two functions allow to record various data from the simulation, organizing them by topics differentiated by their names and attaching them to specific agents. Coupled with an appropriate routine running on the agent that continuously calls the `add_log` function, for example to record the values of the proximeters or the motors through time, this can then be used for generating figures plotting what is happening in the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a routine that record the values sensed by the left and right proximeters of an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a routine using the method we have seen in the last session. Here we call it agent_log \n",
    "def agent_log(agent):\n",
    "    # Retrieve the values of the left and right proximeters:\n",
    "    left, right = agent.sensors()\n",
    "    \n",
    "    # Record the left activation in a topic called \"left_prox\"\n",
    "    agent.add_log(\"left_prox\", left)\n",
    "\n",
    "    # Record the right activation in a topic called \"right_prox\"\n",
    "    agent.add_log(\"right_prox\", right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then attach it on `agent_0` as usual with the `attach_routine` function. Also set both of its motors to 1 to make it move in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the agent_log routine to agent_0, which will be executed every 50 timesteps\n",
    "agent_0.attach_routine(agent_log, interval=50)\n",
    "\n",
    "# Make the agent move forward\n",
    "agent_0.left_motor = agent_0.right_motor = 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set an interval of 50 for the `agent_log` routine, meaning that the left and right proximeter values will be recorded every 50 iterations in the controller loop. We could indicate a smaller interval for more precision but keep in mind that the list of recorded data could then quickly become very large, since the data are recorded continuously at the specified interval. For example, with an interval of 5 and a fps of 30, it will record $(30/5)*60=360$ values each minute of the simulation. \n",
    "\n",
    "You can access to the values recorded from the left proximeter with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"left_prox\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the length of this list, i.e. how many data has been recorded until now, with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(agent_0.get_log(\"left_prox\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clear all logs by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.clear_all_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will erase all the data that `agent_0` has recorded. Recording will however still continue to occur because the `agent_log` routine is still runnning. If you want to stop it you can detach the routine as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.detach_routine(\"agent_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is no longer recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a population of agents foraging for resources according to their energy level (the code below is similar to the one in session 4). In addition we will define a routine continuously recording various data during the simulation, for example proximeter activations or energy levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "First we define the obstacle avoidance behavior for all of the scene obstacles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.print_subtypes_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstacle_avoidance(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"s_obstacles\", \"b_obstacles\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize the energy levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_energy_level = 1.\n",
    "init_energy_level = 0.5\n",
    "\n",
    "for agent in controller.agents:\n",
    "    agent.energy_level = init_energy_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the routine computing the energy level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def energy(agent): \n",
    "    if agent.has_eaten():\n",
    "        # if the agent has eaten a resource since the last execution of the routine, increase its energy level\n",
    "        agent.energy_level += 0.5  # This is equivalent to agent.energy_level = agent.energy_level + 0.5\n",
    "    else:\n",
    "        # decrease energy level\n",
    "        agent.energy_level -= 0.01  # otherwise (nothing eaten), decrease the energy level a bit\n",
    "    # The line below bounds the value of the energy level between 0 and max_energy_level\n",
    "    agent.energy_level = min(max_energy_level, max(agent.energy_level, 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the foraging behavior, which is weighted according to the energy level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foraging(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"resources\"])\n",
    "    left_activation = right\n",
    "    right_activation = left\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `foraging_weight` routine that modulates the weight of the foraging behavior according to the energy level of an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foraging_weight(agent):\n",
    "    # This routine changes the weight of the foraging behavior according to the current energy level\n",
    "    # The lower the energy level, the higher the weight (energy level is bounded between 0 and 1 in the energy routine)\n",
    "    # E.g., if the energy is 1 (maximum value), the behavior weight will be 0 (and vice versa)\n",
    "    agent.change_behavior_weight(foraging, 1 - agent.energy_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we define the routine that will log the data we are interested in (here the left and right activations of the proximeters and the wheels, as well as the energy level of the agent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a routine using the method we have seen in the last session. Here we call it agent_log \n",
    "def agent_log(agent):\n",
    "    # Retrieve the values of the left and right proximeters:\n",
    "    left, right = agent.sensors()\n",
    "    \n",
    "    # Record the left proximeter activation in the topic called \"left_prox\"\n",
    "    agent.add_log(\"left_prox\", left)\n",
    "\n",
    "    # Record the right proximeter activation in the topic called \"right_prox\"\n",
    "    agent.add_log(\"right_prox\", right)\n",
    "\n",
    "    # Record the energy level in the topic called \"energy\"\n",
    "    agent.add_log(\"energy\", agent.energy_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attach the behaviors and routines we have just define on all agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First start sphere apparition in the environment:\n",
    "controller.start_resources_apparition(interval=50)\n",
    "controller.start_eating_mechanism(interval=30)\n",
    "\n",
    "# For all agents\n",
    "for agent in controller.agents:\n",
    "    # Detach all existing behaviors and routines:\n",
    "    agent.detach_all_behaviors()\n",
    "    agent.detach_all_routines()\n",
    "\n",
    "    # Set the diet of the agent to consume resources \n",
    "    agent.diet = [\"resources\"]\n",
    "\n",
    "     # Attach the routines for computing the energy level, modulating the behavior weight and recording data\n",
    "    agent.attach_routine(energy, interval=10)\n",
    "    agent.attach_routine(foraging_weight, interval=10)\n",
    "    agent.attach_routine(agent_log, interval=10)\n",
    "\n",
    "    # Attach the two behaviors we have defined\n",
    "    agent.attach_behavior(obstacle_avoidance)\n",
    "    agent.attach_behavior(foraging)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will start the defined behaviors and routines on the two agents. The `agent_log` routine will record the proximeter activations, as well as the energy level of each agent. Using the produced log, we can now plot those data against time. Let's for example plot the activation of the left proximeter through time. This can be done like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib is the standard Python library for plotting data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the left proximeter value recorded by `agent_0`\n",
    "plt.plot(agent_0.get_log(\"left_prox\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure plot all the left proximeter values recorded from `agent_0`. The x-axis corresponds to when the data was recording (e.g. at `x = 100` we have the 100th recorded value). \n",
    "\n",
    "We can indicate the labels of the x and y axes and provide a title for the figure with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Plot the left proximeter value recorded by `agent_0` and set labels to the x and y axes, as well as a title\n",
    "plt.plot(agent_0.get_log(\"left_prox\"))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Left proximeter\")\n",
    "plt.title(\"Plot of left proximeter activation against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the plot becomes hard to read because there are to many data (e.g. if the range on the x-axis exceeds 1000), we can clear the log. The logging will continue because the routine is still attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in controller.agents:\n",
    "    agent.clear_all_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the energy level of `agent_0` (in case you cleared the plot with the cell above you might want to wait a few seconds so that new data are recorded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the energy level recorded by `agent_0`\n",
    "plt.plot(agent_0.get_log(\"energy\"))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Energy level\")\n",
    "plt.title(\"Plot of energy level against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot two time series on the same plot. Let's plot the energy levels of two agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the energy levels recorded by `agent_0` and `agent_1`\n",
    "plt.plot(agent_0.get_log(\"energy\"))\n",
    "plt.plot(agent_1.get_log(\"energy\"))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Energy level\")\n",
    "plt.title(\"Plot of energy level against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a legend to indicate which line corresponds to which agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the energy levels recorded by `agent_0` and `agent_1`\n",
    "plt.plot(agent_0.get_log(\"energy\"))\n",
    "plt.plot(agent_1.get_log(\"energy\"))\n",
    "plt.legend([\"agent_0\", \"agent_1\"])\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Energy level\")\n",
    "plt.title(\"Plot of energy level against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By right-clicking on the figure and choosing \"Save image as\", you can store it as a PNG image. This is useful if you want to save it for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all. Don't forget to properly close the session when you have finished with the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_server_and_interface(safe_mode=False)\n",
    "controller.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_vivarium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
