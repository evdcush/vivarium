{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging and plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous practical sessions we saw how to define, attach, start, stop and detach routines to the agents. Here we are going to see how to use such routines to record data perceived or produced by the agents. This will allow the plotting of figures in the notebook. This can also be useful to better visualize what is happening in your simulation and help you debugging it. \n",
    "\n",
    "Let's start with a simple example where we record the values returned by both proximeters through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vivarium.controllers.notebook_controller import NotebookController\n",
    "from vivarium.utils.handle_server_interface import start_server_and_interface, stop_server_and_interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start the simulator and create a controller object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_server_and_interface(scene_name=\"session_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller = NotebookController()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will assign variables to each robots present in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0, agent_1, agent_2 = controller.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add some logs to the first agent. Recording data is realized by the `add_log` function of the agent, which require two arguments: the arbitrary label of the recorded data, called the topic, and the data to be recorded. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.add_log(\"test\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This stores the data `1` in a topic that we arbitrarily call `\"test\"`. We can retrieve this data by using the `get_log` function , which requires as argument the name of the topic (`\"test\"` in this example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `agent_0.get_log(\"test\")` returns the list of the data recorded in the topic `\"test\"` by `agent_0`. Here it prints `[1]`, a list containing the only data we have stored before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add another data to the same topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.add_log(\"test\", 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And retrieve the data recorded on this topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second value we have added, `42`, has been appended to the list, which now contains the two recorded data.\n",
    "\n",
    "We can add another value to another topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.add_log(\"another_topic\", 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and retrieve it using `get_log`, this time with the name of this new topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"another_topic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the data recorded before in the topic `\"test\"` is still accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names chosen for the topics are completely arbitrary. They are just tags that you choose for organizing the data according to their source.\n",
    "\n",
    "This two functions allow to record various data from the simulation, organizing them by topics differentiated by their names. Coupled with an appropriate routine running on the agent that continuously calls the `add_log` function, for example to record the values of the proximeters or the motors through time, this can then be used for generating figures plotting what is happening in the simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a routine that record the values sensed by the left and right proximeters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a routine using the method we have seen in the last session. Here we call it agent_log \n",
    "def agent_log(agent):\n",
    "    # Retrieve the values of the left and right proximeters:\n",
    "    left, right = agent.sensors()\n",
    "    \n",
    "    # record the left activation in a topic called \"left_prox\"\n",
    "    agent.add_log(\"left_prox\", left)\n",
    "    # record the right activation in a topic called \"right_prox\"\n",
    "    agent.add_log(\"right_prox\", right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then attach and start it on `agent_0` as usual with the `attach_routine` function. Also set both of its motors to 1 to make it move in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.left_motor = agent_0.right_motor = 1.\n",
    "# Add an interval argument to only log every 50 timesteps\n",
    "agent_0.attach_routine(agent_log, interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set an interval of 20 for the `agent_log` routine, meaning that the left and right proximeter values will be recorded every 20 iterations in the controller loop. We could put a smaller interval for having more precision, but keep in mind that this could cause memory issues, since the data are recorded continuously at the specified interval. For example, with an interval of 10 and a fps of 20, it will record $(20/10)*60=120$ values each minute of the simulation. So it can take a lot of space in memory if you let the simulation running for a long time.\n",
    "\n",
    "You can access to the values recorded from the left proximeter with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent_0.get_log(\"left_prox\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the length of this list with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(agent_0.get_log(\"left_prox\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints all the recorded values for the left proximeter. In case there is too much values to be printed, you can clear the log by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.clear_all_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will erase all the data that `agent_0` has recorded. Recording will however still continue to occur because the `agent_log` routine is still runnning. You can stop the routine as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0.detach_routine(\"agent_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data are not recorded anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a population of agents foraging for spheres according to their energy level as in the last session. We will also define a routine continuously recording various data during the simulation, for example proximeter activations or energy levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First we define the obstacle avoidance behavior for all of the scene obstacles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller.print_subtypes_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstacle_avoidance(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"s_obstacles\", \"b_obstacles\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the routine that compute the energy level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_energy_level = 100.\n",
    "init_energy_level = 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foraging_drive(agent): \n",
    "    if agent.has_eaten():\n",
    "        agent.energy_level += 10  # if the agent has eaten a sphere, increase its energy level by 0.2\n",
    "    else:\n",
    "        agent.energy_level -= 0.01  # otherwise (nothing eaten), decrease the energy level by 0.01\n",
    "    # The line below bounds the value of the energy level between 0 and 1\n",
    "    agent.energy_level = min(max_energy_level, max(agent.energy_level, 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the foraging behavior, which is weighted according to the energy level (due to the last returned value, here `1 - agent.energy_level` because we want the foraging behavior to be more activated when the energy level is lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foraging(agent):\n",
    "    left, right = agent.sensors(sensed_entities=[\"resources\"])\n",
    "    left_activation = right\n",
    "    right_activation = left\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we define the routine that will log the data we are interested in (here the left and right activations of the proximeters and the wheels, as well as the energy level of the agent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a routine using the method we have seen in the last session. Here we call it agent_log \n",
    "def agent_log(agent):\n",
    "    # Retrieve the values of the left and right proximeters:\n",
    "    left, right = agent.sensors()\n",
    "    \n",
    "    # record the left proximeter activation in the topic called \"left_prox\"\n",
    "    agent.add_log(\"left_prox\", left)\n",
    "    # record the right proximeter activation in the topic called \"right_prox\"\n",
    "    agent.add_log(\"right_prox\", right)\n",
    "    # record the energy level in the topic called \"energy\"\n",
    "    agent.add_log(\"energy\", agent.energy_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can attach and start all the behaviors and routines we have just define on the two agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First start sphere apparition in the environment:\n",
    "controller.start_resources_apparition(interval=50)\n",
    "controller.start_eating_mechanism(interval=30)\n",
    "\n",
    "# For all agents\n",
    "for e in controller.agents:\n",
    "    # Detach all existing behaviors and routines:\n",
    "    e.detach_all_behaviors()\n",
    "    e.detach_all_routines()\n",
    "    \n",
    "    e.diet = [\"resources\"]\n",
    "    \n",
    "    # Attach the two behaviors we have defined\n",
    "    e.attach_behavior(obstacle_avoidance)\n",
    "    e.attach_behavior(foraging)\n",
    "    \n",
    "    # Attach the routines for recording data and for computing the energy level\n",
    "    e.attach_routine(agent_log, interval=5)\n",
    "    e.attach_routine(foraging_drive)\n",
    "    \n",
    "    # Set the initial energy level\n",
    "    e.energy_level = init_energy_level\n",
    "    \n",
    "    # start all behaviors and all routines\n",
    "    e.start_all_behaviors()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will start the defined behaviors and routines on the two agents. The `agent_log` routine will record the proximeter activations, as well as the energy level of each agent. Using the produced log, we can now plot those data against time. Let's for example plot the activation of the left proximeter through time. This can be done like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the left proximeter value recorded by `agent_0`\n",
    "plt.plot(agent_0.get_log(\"left_prox\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure plot all the left proximeter values recorded from `agent_1`. The x-axis corresponds to the time step of the recording values and the y-axis corresponds to the value of the left proximeter at each time step. The time step depends on the frequency at which we have run the `agent_log` primitive. Above we have set it to 1Hz (one value recorded per second), so in the figure the x-axis represents seconds. If we would have set the frequency of the `agent_log` routine to 2Hz, each unit on the x-axis would then correspond to half a second.\n",
    "\n",
    "We can indicate the labels of the x and y axes and provide a title for the figure with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Plot the left proximeter value recorded by `agent_0` and set labels to the x and y axes, as well as a title\n",
    "plt.plot(agent_0.get_log(\"left_prox\"))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Left proximeter\")\n",
    "plt.title(\"Plot of left proximeter activation against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This write the labels and the title on the figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the energy level of `agent_1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the energy level recorded by `agent_0`\n",
    "plt.plot(agent_0.get_log(\"energy\"))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Energy level\")\n",
    "plt.title(\"Plot of energy level against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot two time series on the same plot. Let's plot the energy levels of both agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the energy levels recorded by `agent_0` and `agent_2`\n",
    "plt.plot(agent_0.get_log(\"energy\"))\n",
    "plt.plot(agent_2.get_log(\"energy\"))\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Energy level\")\n",
    "plt.title(\"Plot of energy level against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a legend to indicate which line corresponds to which agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below is mandatory to inform the notebook we want to plot directly in it\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the energy levels recorded by `agent_0` and `agent_2`\n",
    "plt.plot(agent_0.get_log(\"energy\"))\n",
    "plt.plot(agent_2.get_log(\"energy\"))\n",
    "plt.legend([\"agent_0\", \"agent_2\"])\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Energy level\")\n",
    "plt.title(\"Plot of energy level against time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By right-clicking on the figure and choosing \"Save image as\", you can store it as a PNG image. This is useful if you want to save it for other purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all. Don't forget to properly close the session when you have finished with the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_server_and_interface()\n",
    "controller.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
